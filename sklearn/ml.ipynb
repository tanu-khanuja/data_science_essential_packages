{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## What is Machine Learning?\n",
    "- **Definition**: A subfield of AI focused on building models to understand and predict data.\n",
    "- **Learning Process**: Models adjust parameters based on data to make predictions.\n",
    "- **Application**: Used to predict outcomes for new, unseen data.\n",
    "\n",
    "## Types of Machine Learning\n",
    "\n",
    "### Supervised Learning\n",
    "- **Data**: Labeled data.\n",
    "- **Tasks**: \n",
    "  - **Classification**: Predict discrete categories (e.g., spam or not spam).\n",
    "  - **Regression**: Predict continuous values (e.g., price prediction).\n",
    "\n",
    "### Unsupervised Learning\n",
    "- **Data**: Unlabeled data.\n",
    "- **Tasks**:\n",
    "  - **Clustering**: Group similar data points (e.g., customer segmentation).\n",
    "  - **Dimensionality Reduction**: Simplify data while preserving important information (e.g., PCA).\n",
    "\n",
    "### Semi-Supervised Learning\n",
    "- **Data**: Partially labeled data.\n",
    "- **Tasks**: Combines aspects of supervised and unsupervised learning, useful when only some data is labeled.\n",
    "\n",
    "## Supervised vs Unsupervised Learning\n",
    "\n",
    "| Feature            | Supervised Learning          | Unsupervised Learning         |\n",
    "|--------------------|------------------------------|-------------------------------|\n",
    "| **Labels**         | Requires labeled data         | Works with unlabeled data      |\n",
    "| **Common Tasks**   | Classification, Regression    | Clustering, Dimensionality Reduction |\n",
    "| **Goal**           | Predict labels for new data   | Find hidden patterns in data   |\n",
    "\n",
    "\n",
    "## Learning Process Flow\n",
    "\n",
    "1. **Data Input**: Labeled or unlabeled data.\n",
    "2. **Model Selection**: Choose supervised or unsupervised learning method.\n",
    "3. **Training**: Adjust model parameters based on data.\n",
    "4. **Prediction**: Use the model to predict or analyze new, unseen data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"/Users/tanukhanuja/data_science_essential_packages/sklearn/Screenshot 2024-09-15 at 9.17.09â€¯AM.png\" alt=\"Alt Text\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Examples of Machine Learning Applications\n",
    "\n",
    "## 1. Classification: Predicting Discrete Labels\n",
    "\n",
    "### Overview\n",
    "- **Task**: Classify new, unlabeled points based on labeled points.\n",
    "- **Data**: Two-dimensional data (x, y positions).\n",
    "- **Labels**: Discrete categories like \"blue\" or \"red\".\n",
    "\n",
    "### Model\n",
    "- **Assumption**: A straight line can separate the two groups.\n",
    "- **Parameters**: Numbers describing the location and orientation of the line.\n",
    "- **Training**: Adjusts parameters to fit the line to the data.\n",
    "- **Prediction**: Use the model to assign labels to new data points by drawing the line.\n",
    "\n",
    "### Real-World Example: Automated Spam Detection\n",
    "- **Features**: Counts of important words/phrases (e.g., \"Viagra,\" \"Nigerian prince\").\n",
    "- **Labels**: \"Spam\" or \"Not Spam\".\n",
    "- **Training**: Labels are determined manually for a sample; the model predicts labels for the rest.\n",
    "- **Effectiveness**: Works well with thousands or millions of features.\n",
    "\n",
    "## Important Classification Algorithms\n",
    "\n",
    "| Algorithm                   | Description                    | \n",
    "|-----------------------------|--------------------------------|\n",
    "| **Gaussian Naive Bayes**    | Probabilistic classification    | \n",
    "| **Support Vector Machines** | Classification using hyperplanes | \n",
    "| **Random Forest Classification** | Ensemble method with decision trees |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Regression: Predicting Continuous Labels\n",
    "\n",
    "### Overview\n",
    "- **Regression**: Predicts continuous values (opposed to classification's discrete categories).\n",
    "\n",
    "Simple Linear Regression\n",
    "- **Concept**: Fit a plane to data where one dimension is continuous. (i.e. label)\n",
    "- **Purpose**: Predict continuous labels for new data points.\n",
    "\n",
    "### Key Algorithms\n",
    "| Algorithm                | Description                      |\n",
    "|--------------------------|----------------------------------|\n",
    "| **Linear Regression**   | Fits a line/plane to data         |\n",
    "| **Support Vector Machines (SVM)** | Handles regression tasks too  |\n",
    "| **Random Forest Regression** | Uses multiple decision trees for prediction |\n",
    "\n",
    "---\n",
    "## 3. Clustering: Inferring Labels on Unlabeled Data\n",
    "\n",
    "- **Clustering**: An unsupervised learning technique to group data into discrete clusters without using known labels.\n",
    "\n",
    "### Key Concepts\n",
    "- **Unsupervised Learning**: Describes data without predefined labels.\n",
    "- **Clustering**: Automatically assigns data to distinct groups based on intrinsic data structure.\n",
    "\n",
    "### Algorithms\n",
    "- **k-Means Clustering**:\n",
    "  - **Method**: Fits a model with k cluster centers.\n",
    "  - **Goal**: Minimize distance of each point from its assigned cluster center.\n",
    "- **Gaussian Mixture Models**: Probabilistic model for clustering based on data distribution.\n",
    "- **Spectral Clustering**: Uses graph theory to identify clusters.\n",
    "\n",
    "### Application\n",
    "- **Use Case**: Extract useful patterns from complex datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Dimensionality Reduction: Inferring Structure of Unlabeled Data\n",
    "\n",
    "- **Dimensionality Reduction**: An unsupervised algorithm that infers labels or information from the dataset's structure.\n",
    "- **Objective**: Extract a low-dimensional representation that retains relevant qualities of the full dataset.\n",
    "\n",
    "##$ Key Concepts\n",
    "- **Abstract Nature**: Seeks to simplify data while preserving its essential features.\n",
    "- **Nonlinear Structure**: Suitable models detect and represent complex, nonlinear structures.\n",
    "\n",
    "### Example\n",
    "- **Data Structure**: Data drawn from a one-dimensional line arranged in a spiral within a two-dimensional space.\n",
    "- **Dimensionality Reduction**: Sensitive to this nonlinear embedded structure to reveal a lower-dimensional representation.\n",
    "\n",
    "### Important Algorithms\n",
    "- **Principal Component Analysis (PCA)**: Reduces dimensionality by identifying principal components.\n",
    "- **Manifold Learning Algorithms**: Includes Isomap and Locally Linear Embedding (LLE), which handle complex data structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
