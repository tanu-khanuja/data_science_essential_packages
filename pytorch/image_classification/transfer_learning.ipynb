{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we learn how to use pretrained models for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, and test data paths\n",
    "train_path = 'Fish-vs-Cats/train'\n",
    "val_path = 'Fish-vs-Cats/val'\n",
    "test_path = 'Fish-vs-Cats/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform\n",
    "transform= transforms.Compose([transforms.Resize((64,64)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                             std= [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train, val, and test datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0, 'fish': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'fish']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader \n",
    "batch_size =64\n",
    "train_dl = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dl = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the pretrained model.\n",
    "There are two common ways to load or transfer a pre-trained model in PyTorch:\n",
    "\n",
    "1. Using GitHub Repository (Torch Hub):\n",
    "- PyTorch Hub allows you to load models directly from public GitHub repositories. This method uses the torch.hub.load() function.\n",
    "- This method is typically used when the model is hosted on GitHub and can be accessed by specifying the repository name and version.\n",
    "\n",
    "\n",
    "2. Directly from torchvision.models:\n",
    "- PyTorchâ€™s torchvision.models module has built-in support for various pre-trained models, and you can load them using the respective function.\n",
    "- This method is more straightforward and doesn't require any external repository. It directly loads pre-trained models available in the torchvision library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/tanukhanuja/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/opt/anaconda3/envs/libraries/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/libraries/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Load ResNet-50 from git repo\n",
    "\n",
    "resnet50 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/tanukhanuja/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'deeplabv3_mobilenet_v3_large',\n",
       " 'deeplabv3_resnet101',\n",
       " 'deeplabv3_resnet50',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'fcn_resnet101',\n",
       " 'fcn_resnet50',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'lraspp_mobilenet_v3_large',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get list of models available in a repo (here pytorch/vision).\n",
    "torch.hub.list('pytorch/vision:v0.10.0')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Directly import using torchvision\n",
    "import torchvision.models as models\n",
    "transfer_model = models.resnet50(pretrained= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transfer_model)  # Layers of ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.conv3.weight\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.0.downsample.0.weight\n",
      "layer1.0.downsample.1.weight\n",
      "layer1.0.downsample.1.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.conv3.weight\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.conv3.weight\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.conv3.weight\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.conv3.weight\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.conv3.weight\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.conv3.weight\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.conv3.weight\n",
      "layer3.0.bn3.weight\n",
      "layer3.0.bn3.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.conv3.weight\n",
      "layer3.1.bn3.weight\n",
      "layer3.1.bn3.bias\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.conv3.weight\n",
      "layer3.2.bn3.weight\n",
      "layer3.2.bn3.bias\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.conv3.weight\n",
      "layer3.3.bn3.weight\n",
      "layer3.3.bn3.bias\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.conv3.weight\n",
      "layer3.4.bn3.weight\n",
      "layer3.4.bn3.bias\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.conv3.weight\n",
      "layer3.5.bn3.weight\n",
      "layer3.5.bn3.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.conv3.weight\n",
      "layer4.0.bn3.weight\n",
      "layer4.0.bn3.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.conv3.weight\n",
      "layer4.1.bn3.weight\n",
      "layer4.1.bn3.bias\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.conv3.weight\n",
      "layer4.2.bn3.weight\n",
      "layer4.2.bn3.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Parameter names that model stores\n",
    "for name, param in transfer_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 7, 7])\n",
      "bn1.weight torch.Size([64])\n",
      "bn1.bias torch.Size([64])\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight torch.Size([256])\n",
      "layer1.0.bn3.bias torch.Size([256])\n",
      "layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight torch.Size([256])\n",
      "layer1.0.downsample.1.bias torch.Size([256])\n",
      "layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight torch.Size([256])\n",
      "layer1.1.bn3.bias torch.Size([256])\n",
      "layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight torch.Size([64])\n",
      "layer1.2.bn1.bias torch.Size([64])\n",
      "layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight torch.Size([64])\n",
      "layer1.2.bn2.bias torch.Size([64])\n",
      "layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight torch.Size([256])\n",
      "layer1.2.bn3.bias torch.Size([256])\n",
      "layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight torch.Size([512])\n",
      "layer2.0.bn3.bias torch.Size([512])\n",
      "layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight torch.Size([512])\n",
      "layer2.0.downsample.1.bias torch.Size([512])\n",
      "layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight torch.Size([512])\n",
      "layer2.1.bn3.bias torch.Size([512])\n",
      "layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight torch.Size([128])\n",
      "layer2.2.bn1.bias torch.Size([128])\n",
      "layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight torch.Size([128])\n",
      "layer2.2.bn2.bias torch.Size([128])\n",
      "layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight torch.Size([512])\n",
      "layer2.2.bn3.bias torch.Size([512])\n",
      "layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight torch.Size([128])\n",
      "layer2.3.bn1.bias torch.Size([128])\n",
      "layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight torch.Size([128])\n",
      "layer2.3.bn2.bias torch.Size([128])\n",
      "layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight torch.Size([512])\n",
      "layer2.3.bn3.bias torch.Size([512])\n",
      "layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight torch.Size([1024])\n",
      "layer3.0.bn3.bias torch.Size([1024])\n",
      "layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight torch.Size([1024])\n",
      "layer3.0.downsample.1.bias torch.Size([1024])\n",
      "layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight torch.Size([1024])\n",
      "layer3.1.bn3.bias torch.Size([1024])\n",
      "layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight torch.Size([256])\n",
      "layer3.2.bn1.bias torch.Size([256])\n",
      "layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight torch.Size([256])\n",
      "layer3.2.bn2.bias torch.Size([256])\n",
      "layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight torch.Size([1024])\n",
      "layer3.2.bn3.bias torch.Size([1024])\n",
      "layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight torch.Size([256])\n",
      "layer3.3.bn1.bias torch.Size([256])\n",
      "layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight torch.Size([256])\n",
      "layer3.3.bn2.bias torch.Size([256])\n",
      "layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight torch.Size([1024])\n",
      "layer3.3.bn3.bias torch.Size([1024])\n",
      "layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight torch.Size([256])\n",
      "layer3.4.bn1.bias torch.Size([256])\n",
      "layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight torch.Size([256])\n",
      "layer3.4.bn2.bias torch.Size([256])\n",
      "layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight torch.Size([1024])\n",
      "layer3.4.bn3.bias torch.Size([1024])\n",
      "layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight torch.Size([256])\n",
      "layer3.5.bn1.bias torch.Size([256])\n",
      "layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight torch.Size([256])\n",
      "layer3.5.bn2.bias torch.Size([256])\n",
      "layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight torch.Size([1024])\n",
      "layer3.5.bn3.bias torch.Size([1024])\n",
      "layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight torch.Size([2048])\n",
      "layer4.0.bn3.bias torch.Size([2048])\n",
      "layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight torch.Size([2048])\n",
      "layer4.0.downsample.1.bias torch.Size([2048])\n",
      "layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight torch.Size([2048])\n",
      "layer4.1.bn3.bias torch.Size([2048])\n",
      "layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight torch.Size([512])\n",
      "layer4.2.bn1.bias torch.Size([512])\n",
      "layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight torch.Size([512])\n",
      "layer4.2.bn2.bias torch.Size([512])\n",
      "layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight torch.Size([2048])\n",
      "layer4.2.bn3.bias torch.Size([2048])\n",
      "fc.weight torch.Size([1000, 2048])\n",
      "fc.bias torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# To get a understanding of parameters and their sizes\n",
    "for name, param in transfer_model.named_parameters():\n",
    "    print(name, param.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameter updation while training\n",
    "for name, param in transfer_model.named_parameters():\n",
    "    param.requires_grad= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will set the gradient upgradation of the pretrained model layers to OFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove batch normalization from freeze parameter list\n",
    "# for name, param in transfer_model.named_parameters():\n",
    "#     if (\"bn\" not in name):\n",
    "#         param.requires_grad= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch normalization parameters are tuned based on the original dataset on which ResNet is trained. If not updated during training based on our dataset, then it can cause us losing some of signal as batchnorm corrects your input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_model.fc.in_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fc is instance variable of the final classifier layer in ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace final classification block\n",
    "import torch.nn as nn \n",
    "\n",
    "transfer_model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(500,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(transfer_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transfer_model.paramaters() will include all the new layers parameters and the layers which are not freezed (i.e. bn layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.bn3.weight\n",
      "layer3.0.bn3.bias\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.bn3.weight\n",
      "layer3.1.bn3.bias\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.bn3.weight\n",
      "layer3.2.bn3.bias\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.bn3.weight\n",
      "layer3.3.bn3.bias\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.bn3.weight\n",
      "layer3.4.bn3.bias\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.bn3.weight\n",
      "layer3.5.bn3.bias\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.bn3.weight\n",
      "layer4.0.bn3.bias\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.bn3.weight\n",
      "layer4.1.bn3.bias\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.bn3.weight\n",
      "layer4.2.bn3.bias\n",
      "fc.0.weight\n",
      "fc.0.bias\n",
      "fc.3.weight\n",
      "fc.3.bias\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "for name, param in transfer_model.named_parameters():\n",
    "    if (('bn' in name) or ('fc' in name)):\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights that will be updated while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(0.7044, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(1.0705, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.8017, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.6097, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.5485, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.5649, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4393, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3933, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4905, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3264, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4638, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4083, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4082, grad_fn=<NllLossBackward0>)\n",
      "Epoch 1/20, loss 0.5561\n",
      "loss=tensor(0.3900, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3370, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2837, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2733, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2796, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2139, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2706, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2365, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3660, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1853, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3041, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2716, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2379, grad_fn=<NllLossBackward0>)\n",
      "Epoch 2/20, loss 0.2807\n",
      "loss=tensor(0.2122, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1923, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1667, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2104, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4049, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2458, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1619, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2280, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1965, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2670, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2541, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3387, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "Epoch 3/20, loss 0.2348\n",
      "loss=tensor(0.3031, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4733, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1714, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2590, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1905, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3376, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2339, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1646, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1128, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1165, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1834, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2874, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2367, grad_fn=<NllLossBackward0>)\n",
      "Epoch 4/20, loss 0.2362\n",
      "loss=tensor(0.1296, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2158, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1368, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2892, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4566, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1828, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3229, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3320, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3685, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1848, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2421, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3541, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1369, grad_fn=<NllLossBackward0>)\n",
      "Epoch 5/20, loss 0.2578\n",
      "loss=tensor(0.1357, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1625, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3206, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1468, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2000, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1545, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2417, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0901, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3761, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2817, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2176, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1679, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2355, grad_fn=<NllLossBackward0>)\n",
      "Epoch 6/20, loss 0.2100\n",
      "loss=tensor(0.1553, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1959, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1869, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1021, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1894, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1803, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1070, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3782, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1912, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2026, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1357, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1835, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1126, grad_fn=<NllLossBackward0>)\n",
      "Epoch 7/20, loss 0.1785\n",
      "loss=tensor(0.1878, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0932, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2041, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1207, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1186, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1154, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1091, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0879, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1356, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1237, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0937, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2082, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3396, grad_fn=<NllLossBackward0>)\n",
      "Epoch 8/20, loss 0.1490\n",
      "loss=tensor(0.0858, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1113, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1534, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1466, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0985, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1627, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1671, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0649, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0879, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1336, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2409, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1848, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2095, grad_fn=<NllLossBackward0>)\n",
      "Epoch 9/20, loss 0.1421\n",
      "loss=tensor(0.0620, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1466, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0911, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1086, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2150, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0943, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0958, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1239, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1461, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1198, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1565, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.4315, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1560, grad_fn=<NllLossBackward0>)\n",
      "Epoch 10/20, loss 0.1498\n",
      "loss=tensor(0.0751, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2062, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2157, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0951, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1136, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1153, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1851, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1603, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1337, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1422, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1159, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2723, grad_fn=<NllLossBackward0>)\n",
      "Epoch 11/20, loss 0.1519\n",
      "loss=tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1297, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3237, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1627, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1559, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2395, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1637, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0703, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2270, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2577, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2481, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0911, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1290, grad_fn=<NllLossBackward0>)\n",
      "Epoch 12/20, loss 0.1801\n",
      "loss=tensor(0.1051, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0592, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1173, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1079, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0670, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1597, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1572, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1012, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0704, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1337, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1100, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0987, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0370, grad_fn=<NllLossBackward0>)\n",
      "Epoch 13/20, loss 0.1019\n",
      "loss=tensor(0.0997, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2154, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0936, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2113, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0653, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0867, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0427, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2189, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2456, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2602, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0808, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0564, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3935, grad_fn=<NllLossBackward0>)\n",
      "Epoch 14/20, loss 0.1592\n",
      "loss=tensor(0.1000, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1080, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1216, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1007, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1674, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1109, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0546, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2168, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0975, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1728, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1390, grad_fn=<NllLossBackward0>)\n",
      "Epoch 15/20, loss 0.1154\n",
      "loss=tensor(0.1010, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2464, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0842, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0829, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1159, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0870, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1088, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2630, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2142, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0833, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1774, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3841, grad_fn=<NllLossBackward0>)\n",
      "Epoch 16/20, loss 0.1617\n",
      "loss=tensor(0.2158, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2986, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0681, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1535, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1365, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2103, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2403, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1053, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0629, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0691, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0841, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1985, grad_fn=<NllLossBackward0>)\n",
      "Epoch 17/20, loss 0.1552\n",
      "loss=tensor(0.0958, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1034, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0847, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0733, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0869, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0851, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1355, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1379, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1903, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1402, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0808, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0640, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1125, grad_fn=<NllLossBackward0>)\n",
      "Epoch 18/20, loss 0.1070\n",
      "loss=tensor(0.0790, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1378, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0825, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0627, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1463, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1445, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0959, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0943, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1078, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.2018, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0794, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.3246, grad_fn=<NllLossBackward0>)\n",
      "Epoch 19/20, loss 0.1222\n",
      "loss=tensor(0.1076, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0386, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1613, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0597, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0620, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0699, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1056, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0528, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.0603, grad_fn=<NllLossBackward0>)\n",
      "loss=tensor(0.1430, grad_fn=<NllLossBackward0>)\n",
      "Epoch 20/20, loss 0.0781\n"
     ]
    }
   ],
   "source": [
    "# Train the mnodel\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    transfer_model.train() # Set model to training mode\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for input, label in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        output = transfer_model(input)\n",
    "        loss = criterion(output, label)\n",
    "        # print(f\"{loss=}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss/len(train_dl)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, loss {average_loss:.4f}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6642313748598099, Accuracy: 87.9630%\n"
     ]
    }
   ],
   "source": [
    "# Applying model on validation data\n",
    "transfer_model.eval()\n",
    "val_loss = 0\n",
    "correct_pred = 0\n",
    "total_pred = 0\n",
    "for batch in val_dl:\n",
    "    input, label = batch\n",
    "    output = transfer_model(input)\n",
    "    # print(output)\n",
    "    loss = criterion(output, label)\n",
    "    val_loss += loss.item()\n",
    "    values, indices = torch.max(output, 1)  # maximum values in each row (dim = 1)\n",
    "    total_pred += label.size(0)\n",
    "    correct_pred += (indices==label).sum().item()\n",
    "\n",
    "accuracy = (correct_pred/total_pred) * 100\n",
    "print(f\"Validation loss: {val_loss}, Accuracy: {accuracy:.4f}%\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.125%\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "transfer_model.eval()\n",
    "running_loss = 0\n",
    "total_pred = 0\n",
    "correct_pred = 0\n",
    "\n",
    "for batch in test_dl:\n",
    "    input, label = batch\n",
    "    output = transfer_model(input)\n",
    "    loss = criterion(output, label)\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    values, indices = torch.max(output, 1)\n",
    "    total_pred += label.size(0)\n",
    "    correct_pred += (indices==label).sum().item()\n",
    "\n",
    "accuracy = (correct_pred/total_pred)*100\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libraries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
